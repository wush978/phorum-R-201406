---
title       : Large Scale Model Fitting with R
subtitle    : 
author      : Wush Wu
job         : Taiwan R User Group
framework   : io2012        # {io2012, html5slides, shower, dzslides, ...}
highlighter : highlight.js  # {highlight.js, prettify, highlight}
hitheme     : zenburn       # 
widgets     : [mathjax]            # {mathjax, quiz, bootstrap}
mode        : selfcontained # {standalone, draft}
license: by-nc-sa
logo: Taiwan-R-logo.png
--- &vcenter .large

很多人都在詬病R 無法處理大量的數據

--- &vcenter .large

但是只要用對R 的包

R 是可以處理大量的數據

--- &vcenter .large

今天我想跟大家分享

運用R 建立商用推薦引擎的心得

主要是靠著`Rcpp`和`pbdMPI`等包

打造可擴放性的學習模組

--- &twocol

*** =left

## 關於講者

- 清華大學統計所碩士
- 臺灣大學電機所博士生
- 宇匯知識科技
- Taiwan R User Group Officer

*** =right

<img src="assets/img/farmer.jpg" class="fit100"/>

--- &vcenternobg .large

```{r setup, include=FALSE,echo = F, message = F, warning = F, tidy = F, cache=FALSE}
# make this an external chunk that can be included in any file
library(xtable)
library(rbenchmark)
library(reshape2)
library(knitr)
library(methods)
options(width = 100,digits=3)
opts_chunk$set(message = FALSE, eval=TRUE,fig.align = "center", warning = FALSE, comment = NA, dpi = 100, fig.width=6, fig.height=4.5,tidy = FALSE, cache = FALSE, echo=FALSE)

options(xtable.type = 'html')
knit_hooks$set(inline = function(x) {
  if(is.numeric(x)) {
    round(x, getOption('digits'))
  } else {
    paste(as.character(x), collapse = ', ')
  }
})
knit_hooks$set(plot = knitr:::hook_plot_html)
library(bibtex)
library(knitcitations)
bib <- read.bib("index.bib")
```

<img src="assets/img/MLDMMonday.jpg" class="grayscale fit100" />

Taiwan R User Group

MLDMMonday: 每週一分享資料相關議題

主題包含但不限於：

R 套件使用

機器學習和統計模型

--- &vcenter .large

實際的數據和課本上的數據是不一樣的

--- &twocolvcenter

<img src="assets/img/datanoise.png" class="fit100"/>

*** =left

## 實際的數據

- 亂、充滿錯誤
- 不停的變動
- 不知道怎樣才算好
    - 只能不斷精益求精

*** =right

## 課本的數據

- 乾淨
- 靜止
- 需要複雜的算法

--- &vcenter .large

今天從這樣的數據開始

```{r demo_data, results='asis'}
df <- read.table("demo_data.txt")
colnames(df) <- c("is_click", "show_time", "", "client_ip")
df$adid <- rownames(df)
rownames(df) <- NULL
df$show_time <- paste(df[,2], df[,3])
df[[3]] <- NULL
print(xtable(df), type="html")
```
<br/>
以“預測點擊發生的機率”為例

--- &twocol .large

## 問題的建模

```{r demo_data2, dependson="demo_data", results='asis'}
print(xtable(df), type="html")
```
<h2>$$\Downarrow$$</h2>
<h2>$$P(y|x) = \frac{1}{1 + e^{-yw^Tx}}$$</h2>

--- &vcenter .large

$$w^Tx$$

<img src="assets/img/MatVecMult01.gif" class="fit100"/>

--- &vcenter .large

iris

```{r iris_way, echo=TRUE}
head(model.matrix(Species ~ ., iris))
```

--- &vcenter .large

實際的資料

有 $10^{9+}$ 筆資料

有 $10^{3+}$ 筆廣告

每種類別變量可能到 $10^{3}$ 類別

--- &vcenter .large

`model.matrix`的後果：

一個Covariate下

至少需要 $10^9 \times (10^3...)$ 個位元

也就是 $`r 10^12 / 2^30 / 8`$ GB的記憶體

--- &vcenter .large

開始抱怨了!

### R 不能處理大量的數據

### R 會吃很多記憶體

### 使用R 跑不動，使用其他工具就跑得動

<img src="assets/img/Risbad.png" class="fit50"/>

--- &vcenter .large

請使用和其他工具一樣的資料結構:

這種狀況，應該使用`稀疏矩陣`

<img src="assets/img/sparsematrix.png" class="fit100"/>

--- &twocolvcenter .large 

稀疏矩陣

```{r sparse_matrix_echo, echo=TRUE, eval=FALSE, cache=TRUE}
m1 <- matrix(0, 5, 5);m1[1, 4] <- 1
m1
library(Matrix)
m2 <- Matrix(0, 5, 5, sparse=TRUE)
m2[1,4] <- 1
m2
```

*** =left

```{r, echo=FALSE}
n <- 1
m1 <- matrix(0, 5, 5);m1[1, 4] <- 1
m1
```

*** =right

```{r, echo=FALSE, dependson="sparse_matrix_echo"}
library(Matrix)
m2 <- Matrix(0, 5, 5, sparse=TRUE)
m2[1,4] <- 1
m2
```

--- &vcenter .large

在我手上的資料上

大概可以省下 $10^2 \sim 10^3$ 倍記憶體

而且可以大幅度加快運算效能!

--- &vcenter .large

如果`m1`, `m2`是 $10^4 \times 10^4$ 的矩陣:

```{r sparse_mat_efficiency, cache=TRUE}
library(rbenchmark)
n <- 4
m1 <- matrix(0, 10^n, 10^n);m1[1, 4] <- 1
m2 <- Matrix(0, 10^n, 10^n, sparse=TRUE)
r <- rnorm(10^n)
benchmark(
  m1 %*% r,
  m2 %*% r)
```

--- &vcenter .large

可以利用`Rcpp`將C的實作暴露到R中

可以利用`Rcpp`做記憶體的重復使用

```{r rcpp_matrix_multiplication_eval, cache=TRUE, engine='Rcpp'}
#include <Rcpp.h>
using namespace Rcpp;
// [[Rcpp::export]]
SEXP XTv(S4 m, NumericVector v, NumericVector& retval) {
  int
    *i = INTEGER(wrap(m.slot("i"))),
    i_len = Rf_length(wrap(m.slot("i"))),
    *p = INTEGER(wrap(m.slot("p"))),
    p_len = Rf_length(wrap(m.slot("p")));
    NumericVector x = wrap(m.slot("x"));
  IntegerVector dim(wrap(m.slot("Dim")));
  if (v.size() != dim[0]) throw std::invalid_argument("");
  for(int j = 0,k = 0;j < p_len - 1;j++) {
    while(k < p[j+1]) {
      retval[j] += x[k]*v[i[k++]];
    }
  }
  return retval;
}
```

```{r rcpp_matrix_multiplication_benchmark, cache=TRUE, dependson=c("sparse_mat_efficiency","rcpp_matrix_multiplication_eval"), echo=FALSE}
retval <- numeric(10^n)
benchmark(
  m2 %*% r,
  XTv(m2, r, retval))
```

--- &vcenter .large

在現代的Rcpp架構下

將C++函數放到R中變得很簡單

我們只需要專注在算法上

```{r rcpp_matrix_multiplication_echo, cache=TRUE, engine='Rcpp', echo=TRUE}
#include <Rcpp.h>
using namespace Rcpp;
// [[Rcpp::export]]
SEXP XTv(S4 m, NumericVector v, NumericVector& retval) {
  //...
}
```

--- &vcenter .large

社群的線上教學：[Rcpp/C++ 線上講座](https://taiwanrusergroup.hackpad.com/Rcpp-C--CxNKWGJ9bzQ)

<img src="assets/img/rcpp_tutorial.png" class="fit50"/>

--- &vcenter .large

再透過`pbdMPI`開發分散式矩陣乘法

利用更多CPU和更多記憶體提升效能

--- &vcenter .large

$$\left(\begin{array}{c}X_1 \\ X_2\end{array}\right) v = \left(\begin{array}{c}X_1 v \\ X_2 v\end{array}\right)$$

$$\left(v_1 , v_2\right) \left(\begin{array}{c}X_1 \\ X_2\end{array}\right) = v_1 X_1 + v_2 X_2$$

--- &vcenternobg

<img src="assets/img/hadoopvsmpi.png" class="grayscale fit100"/>

--- &vcenter .large

`pbdMPI`是[pbdR(Programming with Big Data in R)](http://r-pbd.org/)專案的套件之一

<img src="assets/img/pbdMPI.png" class="fit50" />

--- &twocolvcenter .large

```
sudo apt-get install openmpi-bin openmpi-common libopenmpi-dev
```

```{r, eval=FALSE, echo=TRUE}
install.packages("pbdMPI")
```

*** =left

## pbdMPI的優點

### 好安裝
### 好開發

*** =right

```{r pbdMPI_demo, eval=FALSE, echo=TRUE, tidy.opts=list(width.cutoff=20L)}
library(pbdMPI)
.rank <- comm.rank()
filename <- sprintf("%d.csv", .rank)
data <- read.csv(filename)
target <- reduce(sum(data$value), op="sum")
finalize()
```

--- &twocolvcenter .large

*** =left

## 最佳化算法

### 迭代次數少
### 不用計算Hessian矩陣
### 已有很棒的實作[LIBLINEAR](http://www.csie.ntu.edu.tw/~cjlin/liblinear/)

*** =right

<h3>`r citet(bib["Lin:2007:TRN:1273496.1273567"], format_inline_fn = function(x) paste(knitcitations:::format_authoryear_p(x), x$title))`</h3>

--- &vcenter .large

為了加強效能

並且能夠更方便的更改模型

我們自己包LIBLINEAR到R中

--- &vcenter .large

## LIBLINEAR 原始碼中的 `tron.h`

```{r tron, engine='Rcpp', eval=FALSE, echo=TRUE}
class TRON
{
public:
  TRON(const function *fun_obj, double eps = 0.1, int max_iter = 1000);
  ~TRON();

  void tron(double *w);
	void set_print_string(void (*i_print) (const char *buf));

private:
	//...
};
```

- TRON是最佳化的核心算法的實作
- TRON沒有牽涉到資料，甚至沒有牽涉到Loss Function
- `function`提供了一個界面

--- &vcenter

## 界面：`function`

```{r function_interface, engine='Rcpp', eval=FALSE, echo=TRUE}
class function
{
public:
  virtual double fun(double *w) = 0 ;
  virtual void grad(double *w, double *g) = 0 ;
	virtual void Hv(double *s, double *Hs) = 0 ;

	virtual int get_nr_variable(void) = 0 ;
	virtual ~function(void){}
};
```

- `fun`代表objective function
- `grad`是`fun`的gradient
- `Hv`是`fun`的hessian乘上一個向量

--- &twocolvcenter .large

## 利用`Rcpp Modules`把`function`暴露到R中

*** =left

### 實作Rfunction

```{r Rfunction, engine='Rcpp', eval=FALSE, echo=TRUE}
class Rfunction : public ::function {
  Rcpp::Function _fun, _grad, _Hv;
  Rcpp::NumericVector _w, _s;
  
  Rfunction(SEXP fun, SEXP grad, SEXP Hv, int n) 
  : _fun(fun), _grad(grad), _Hv(Hv), _w(n), _s(n) { }
  
  //...
};

SEXP tron//...
```

*** =right

將Rfunction暴露出來

```{r Rfunction_module, engine='Rcpp', eval=FALSE, echo=TRUE}
RCPP_MODULE(HsTrust) {  
  class_<Rfunction>("HsTrust")
	.constructor<SEXP, SEXP, SEXP, int>()
	.property("n", &Rfunction::get_nr_variable, 
    "Number of parameters")
	.method("tron", &tron)
	.method("tron_with_begin", 
    &tron_with_begin)
	;	
}
```

--- &twocolvcenter .large

*** =left

實作的結果可包裝成[套件](https://bitbucket.org/wush978/largescalelogisticregression/src/4daf9c5bba5cd0e4f35afd813866e6da72ca92bb/?at=hstrust)


```{r, eval=FALSE, echo=TRUE}
library(devtools)
install_bitbucket(
  repo="largescalelogisticregression", 
  username="wush978", ref="hstrust")
```

*** =right

使用

```{r, eval = FALSE, echo=TRUE}
library(HsTrust)

beta <- 1
fun <- function(w) 
  sum((w-beta)^4)

grad <- function(w)
  4 * (w-beta)^3

Hs <- function(w, s) 
  12 * (w-beta)^2 * s

obj <- new(HsTrust, fun, grad, Hs, 1)
print(r <- obj$tron(1e-4, TRUE))
```

--- &vcenter

```{r, eval = FALSE, echo=TRUE}
library(HsTrust)
# ...
print(r <- obj$tron(1e-4, TRUE))
```

```{r, eval = TRUE, echo=FALSE}
library(HsTrust)

beta <- 1
fun <- function(w) 
  sum((w-beta)^4)

grad <- function(w)
  4 * (w-beta)^3

Hs <- function(w, s) 
  12 * (w-beta)^2 * s

obj <- new(HsTrust, fun, grad, Hs, 1)
print(r <- obj$tron(1e-4, TRUE))
```


--- &vcenter .large

結合`pbdMPI`和`Rcpp Modules`

讓TRON呼叫分散式的運算系統

SPMD架構，無master，一次資料交換

```{r, eval=FALSE, echo=TRUE}
objective_function <- function(w) {
  logger(sum(w))
  regularization <- sum((w - prior)^2) / 2
  lik <- sum(C * log(1 + exp(- y.value * Xv(X, w))))
  lik.all <- allreduce(x = lik, x.buffer = buffer.0, op = "sum")
  return(regularization + lik.all[1])
}

hs <- new(HsTrust, objective_function, ...)
```

--- &vcenter .large

SPMD架構

<img src="assets/img/SPMD.png" class="fit100"/>


--- &vcenter .large

`objective_function`非常易於修改

所以我們能將注意力專注於模型上

```{r, eval=FALSE, echo=TRUE}
objective_function <- function(w) {
  logger(sum(w))
  regularization <- sum((w - prior)^2) / 2
  lik <- sum(C * log(1 + exp(- y.value * Xv(X, w))))
  lik.all <- allreduce(x = lik, x.buffer = buffer.0, op = "sum")
  return(regularization + lik.all[1])
}
```

--- &vcenter .large

終於跨過資料量的門檻了...

該看看資料了！

--- .dark .segue

## 資料越大，結果就會越好嗎？

---

<img src="assets/img/datasize.png" class="fit100"/>

--- .dark .segue

## 不同的模型對預測會有影響嗎？

--- &vcenter .large

因子的組合

<img src="assets/img/factors.png" class="fit100" />

--- &vcenter .large

實驗結果

```{r exp, echo=FALSE, results='asis'}
print(xtable(head(read.csv("exp.csv", header=TRUE), 20), digits=4), type="html")
```

--- &vcenter .large

分析

### 感謝R 強大的分析功能

```{r result, echo=FALSE, results='asis'}
print(xtable(read.csv("result.csv", sep="\t", check.names=FALSE), digits=4), type="html")
```

### 平均來說FeatureSet B 好 $0.5\%$

--- &vcenter .large

<img src="assets/img/cycle.png" class="fit100" />

--- &vcenter .large

成果

```{r, echo=FALSE}
library(ggplot2)
df2 <- readRDS("../result.Rds")
ggplot(df2, aes(x=date, y=ratio)) +
  geom_line()
```

--- .dark .segue

## 其他的工程面分享

### 處理大量數據需要很多工程

--- &vcenter .large

R Packages + Git + Jenkins:

開發後自動測試、部署和版本控制

<img src="assets/img/jenkins.png" class="fit50"/>

--- &vcenter .large

利用Spark做Data Cleaning

<img src="assets/img/Spark.png" class="fit50"/>

--- &vcenter .large

R + [rjson]() + [awscli](https://aws.amazon.com/cn/cli/)

自動利用AWS建立雲端實驗用Cluster

```{r, eval=FALSE, echo=TRUE}
ec2_request_spot_instances <- function(spot_price, instance_count, launch_specification = list()) {
  write(toJSON(launch_specification), file=(json.path <- tempfile()))
  cmd <- sprintf("aws ec2 request-spot-instances --spot-price %f --instance-count %d --launch-specification %s", spot_price, instance_count, sprintf("file://%s", json.path))
  system_collapse(cmd)
}
```

--- &vcenter .large

R 是可以對大量數據進行處理：

### 使用`Matrix`套件的稀疏矩陣
### `Rcpp`高效能的使用記憶體
### `Rcpp`整合第三方的庫
### `pbdMPI`建立分散式平行運算叢集

--- &vcenter .large

關於今天分享的工作

感謝兩位同學Y.-C. Juan, Y. Zhuang

和我在Bridgewell Inc.的合作

--- &vcenter .large

Q&A
