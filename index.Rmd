---
title       : Large Scale Learning in R
subtitle    : 
author      : Wush Wu
job         : Taiwan R User Group
framework   : io2012        # {io2012, html5slides, shower, dzslides, ...}
highlighter : highlight.js  # {highlight.js, prettify, highlight}
hitheme     : tomorrow       # 
widgets     : [mathjax]            # {mathjax, quiz, bootstrap}
mode        : selfcontained # {standalone, draft}
license: by-nc-sa
logo: Taiwan-R-logo.png
--- .quote .segue .nobackground .dark
```{r setup, include=FALSE,echo = F, message = F, warning = F, tidy = F, cache=FALSE}
# make this an external chunk that can be included in any file
library(xtable)
library(rbenchmark)
library(reshape2)
library(knitr)
library(methods)
options(width = 100,digits=3)
opts_chunk$set(message = FALSE, eval=TRUE,fig.align = "center", warning = FALSE, comment = NA, dpi = 100, fig.width=6, fig.height=4.5,tidy = FALSE, cache = FALSE, echo=FALSE)

options(xtable.type = 'html')
knit_hooks$set(inline = function(x) {
  if(is.numeric(x)) {
    round(x, getOption('digits'))
  } else {
    paste(as.character(x), collapse = ', ')
  }
})
knit_hooks$set(plot = knitr:::hook_plot_html)
library(bibtex)
library(knitcitations)
bib <- read.bib("index.bib")
```

--- .dark .segue .quote

## Large Scale Learning in R

--- &vcenter .large

很多人都在詬病R 無法處理大量的數據

--- &vcenter .large

但是只要用對R 的包

R 是可以處理大量的數據

--- &vcenter .large

今天我想跟大家分享

運用R 建立商用推薦引擎的心得

主要是靠著`Rcpp`和`pbdMPI`等包

打造可扩放性的學習模組

--- &vcenter .large

實際的數據和課本上的數據是不一樣的

--- &twocolvcenter

*** =left

## 實際的數據

- 亂、充滿錯誤
- 不停的變動
- 不知道怎樣才算好
    - 只能不斷精益求精

*** =right

## 課本的數據

- 乾淨
- 靜止
- 需要複雜的演算法

--- &vcenter .large

今天從這樣的數據開始

```{r demo_data, results='asis'}
df <- read.table("demo_data.txt")
colnames(df) <- c("is_click", "show_time", "", "client_ip")
df$adid <- rownames(df)
rownames(df) <- NULL
df$show_time <- paste(df[,2], df[,3])
df[[3]] <- NULL
print(xtable(df), type="html")
```
<br/>
以「預測點擊發生的機率」為例

--- &twocol .large

## 問題的建模

```{r demo_data2, dependson="demo_data", results='asis'}
print(xtable(df), type="html")
```
<h2>$$\Downarrow$$</h2>
<h2>$$P(y|x) = \frac{1}{1 + e^{-yw^Tx}}$$</h2>

--- &vcenter .large

$$w^Tx$$

--- &vcenter .large

iris

```{r iris_way, echo=TRUE}
head(model.matrix(Species ~ ., iris))
```

--- &vcenter .large

實際的資料

有 $10^{9+}$ 筆資料

有 $10^{3+}$ 筆廣告

每種類別變數可能到 $10^{3}$ 類別

--- &vcenter .large

`model.matrix`的後果：

至少需要 $10^9 \times (10^3...)$ 個位元

也就是 $`r 10^12 / 2^30 / 8`$ GB的記憶體

--- &vcenter .large

開始抱怨了!

### R 不能處理大量的數據

### R 會吃很多記憶體

### 使用R 跑不動，使用其他工具就跑得動

--- &vcenter .large

請使用和其他工具一樣的資料結構:

這種狀況，應該使用稀疏矩阵

--- &twocolvcenter

*** =left

```{r mem1, echo=TRUE}
library(Matrix); data(KNex)
class(KNex$mm)[1]
object.size(KNex$mm)
```

*** =right

```{r mem2, echo=TRUE, dependson="mem1"}
mm <- as(KNex$mm, "matrix")
class(mm)
object.size(mm)
```

--- &vcenter .large

在我手上的資料上

大概可以省下 $10^2 \sim 10^3$ 倍記憶體

`並且可以大幅加快運算效能`

--- &vcenter .large

還可用`Rcpp`實做矩陣-向量的乘法

我們的實作和BLAS庫比較：

```
nnz = 1.000000e+06, rows = 1.000000e+05, cols = 1.000000e+03, 
density = 1.000000e-02, times = 100, nr_threads = 1
generating data...done 453ms
CSR Xv:  388ms
CSR XTv: 288ms
CSR X^TDXv: 488ms
CSR X^TDXv (ACC): 367ms
CSR Xv (MKL):  468ms
CSR XTv (MKL): 482ms
CSR X^TDXv (MKL): 529ms
CSR Xv (NIST):  398ms
CSR XTv (NIST): 461ms
error: 0.000000
```

--- &vcenter .large

再透過`pbdMPI`開發分散式矩陣乘法

利用更多CPU和更多記憶體提升效能

$$\left(\begin{array}{c}X_1 \\ X_2\end{array}\right) w = \left(\begin{array}{c}X_1 w \\ X_2 w\end{array}\right)$$

--- &vcenter .large

`pbdMPI`是[pbdR(Programming with Big Data in R)](http://r-pbd.org/)專案的套件之一

--- &twocolvcenter .large

*** =left

## pbdMPI的優點

### 好安裝
### 好開發

*** =right

```{r pbdMPI_demo, eval=FALSE, echo=TRUE, tidy.opts=list(width.cutoff=20L)}
library(pbdMPI)
.rank <- comm.rank()
filename <- sprintf("%d.csv", .rank)
data <- read.csv(filename)
target <- reduce(sum(data$value), op="sum")
finalize()
```

--- &twocolvcenter .large

*** =left

## 最佳化演算法

### 快速
### 不用計算Hessian矩陣
### 很棒的實作[LIBLINEAR](http://www.csie.ntu.edu.tw/~cjlin/liblinear/)

*** =right

<h3>`r citet(bib["Lin:2007:TRN:1273496.1273567"], format_inline_fn = function(x) paste(knitcitations:::format_authoryear_p(x), x$title))`</h3>

--- &vcenter .large

為了加強效能

並且能夠更方便的更改模型

我們自己包LIBLINEAR到R中

--- &vcenter .large

## LIBLINEAR 原始碼中的 `tron.h`

```{r tron, engine='Rcpp', eval=FALSE, echo=TRUE}
class TRON
{
public:
  TRON(const function *fun_obj, double eps = 0.1, int max_iter = 1000);
  ~TRON();

	void tron(double *w);
	void set_print_string(void (*i_print) (const char *buf));

private:
	//...
};
```

- TRON是最佳化的核心演算法的實作
- TRON沒有牽涉到資料，甚至沒有牽涉到Loss Function
- `function`提供了一個界面

--- &vcenter

## 界面：`function`

```{r function_interface, engine='Rcpp', eval=FALSE, echo=TRUE}
class function
{
public:
  virtual double fun(double *w) = 0 ;
  virtual void grad(double *w, double *g) = 0 ;
	virtual void Hv(double *s, double *Hs) = 0 ;

	virtual int get_nr_variable(void) = 0 ;
	virtual ~function(void){}
};
```

- `fun`代表objective function
- `grad`是`fun`的gradient
- `Hv`是`fun`的hessian乘上一個向量

--- &twocolvcenter .large

## 利用`Rcpp Modules`把`function`暴露到R中

*** =left

### 實作Rfunction

```{r Rfunction, engine='Rcpp', eval=FALSE, echo=TRUE}
class Rfunction : public ::function {
  Rcpp::Function _fun, _grad, _Hv;
  Rcpp::NumericVector _w, _s;
  
  Rfunction(SEXP fun, SEXP grad, SEXP Hv, int n) 
  : _fun(fun), _grad(grad), _Hv(Hv), _w(n), _s(n) { }
  
  //...
};

SEXP tron//...
```

*** =right

將Rfunction暴露出來

```{r Rfunction_module, engine='Rcpp', eval=FALSE, echo=TRUE}
RCPP_MODULE(HsTrust) {  
  class_<Rfunction>("HsTrust")
	.constructor<SEXP, SEXP, SEXP, int>()
	.property("n", &Rfunction::get_nr_variable, 
    "Number of parameters")
	.method("tron", &tron)
	.method("tron_with_begin", 
    &tron_with_begin)
	;	
}
```

--- &twocolvcenter .large

*** =left

實作的結果可包裝成[套件](https://bitbucket.org/wush978/largescalelogisticregression/src/4daf9c5bba5cd0e4f35afd813866e6da72ca92bb/?at=hstrust)


```{r, eval=FALSE, echo=TRUE}
library(devtools)
install_bitbucket(
  repo="largescalelogisticregression", 
  username="wush978", ref="hstrust")
```

*** =right

使用

```{r, eval = FALSE, echo=TRUE}
library(HsTrust)

beta <- 1
fun <- function(w) 
  sum((w-beta)^4)

grad <- function(w)
  4 * (w-beta)^3

Hs <- function(w, s) 
  12 * (w-beta)^2 * s

obj <- new(HsTrust, fun, grad, Hs, 1)
print(r <- obj$tron(1e-4, TRUE))
```

--- &vcenter

```{r, eval = FALSE, echo=TRUE}
library(HsTrust)
# ...
print(r <- obj$tron(1e-4, TRUE))
```

```{r, eval = TRUE, echo=FALSE}
library(HsTrust)

beta <- 1
fun <- function(w) 
  sum((w-beta)^4)

grad <- function(w)
  4 * (w-beta)^3

Hs <- function(w, s) 
  12 * (w-beta)^2 * s

obj <- new(HsTrust, fun, grad, Hs, 1)
print(r <- obj$tron(1e-4, TRUE))
```


--- &vcenter .large

結合`pbdMPI`和`Rcpp Modules`

讓TRON呼叫分散式的運算系統

SPMD架構，無master，一次資料交換

```{r, eval=FALSE, echo=TRUE}
objective_function <- function(w) {
  logger(sum(w))
  regularization <- sum((w - prior)^2) / 2
  lik <- sum(C * log(1 + exp(- y.value * Xv(X, w))))
  lik.all <- allreduce(x = lik, x.buffer = buffer.0, op = "sum")
  return(regularization + lik.all[1])
}

hs <- new(HsTrust, objective_function, ...)
```

--- &vcenter .large

`objective_function`非常易於修改

所以我們能將注意力專注於模型上

```{r, eval=FALSE, echo=TRUE}
objective_function <- function(w) {
  logger(sum(w))
  regularization <- sum((w - prior)^2) / 2
  lik <- sum(C * log(1 + exp(- y.value * Xv(X, w))))
  lik.all <- allreduce(x = lik, x.buffer = buffer.0, op = "sum")
  return(regularization + lik.all[1])
}
```

--- &vcenter .large

終於跨過資料量的門檻了...

該看看資料了！

--- .dark .segue

## 資料越大，結果就會越好嗎？

---

<img src="assets/img/datasize.png" class="fit100"/>

--- .dark .segue

## 不同的模型對預測會有影響嗎？

--- &vcenter .large

因子的組合

<img src="assets/img/factors.png" class="fit100" />

--- &vcenter .large

實驗結果

```{r exp, echo=FALSE, results='asis'}
print(xtable(head(read.csv("exp.csv", header=TRUE), 20), digits=4), type="html")
```

--- &vcenter .large

分析

### 感謝R 強大的分析功能

```{r result, echo=FALSE, results='asis'}
print(xtable(read.csv("result.csv", sep="\t", check.names=FALSE), digits=4), type="html")
```

### 平均來說FeatureSet B 好 $0.5\%$

--- &vcenter .large

<img src="assets/img/cycle.png" class="fit100" />

--- &vcenter .large

成果

```{r, echo=FALSE}
library(ggplot2)
df2 <- readRDS("../result.Rds")
ggplot(df2, aes(x=date, y=ratio)) +
  geom_line()
```

--- .dark .segue

## 其他和的工程面

--- &vcenter .large

